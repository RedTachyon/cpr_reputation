{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import UnifiedLogger\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "from cpr_reputation.environments import HarvestEnv\n",
    "\n",
    "defaults_ini = {\n",
    "    \"num_agents\": 4,\n",
    "    \"size\": (20, 20),\n",
    "    \"sight_width\": 5,\n",
    "    \"sight_dist\": 10,\n",
    "    \"num_crosses\": 4,\n",
    "}\n",
    "\n",
    "register_env(\"harvest\", lambda config: HarvestEnv(config, **defaults_ini))\n",
    "\n",
    "walker1 = (\n",
    "    None,\n",
    "    Box(\n",
    "        0.0,\n",
    "        1.0,\n",
    "        (defaults_ini[\"sight_dist\"], 2 * defaults_ini[\"sight_width\"] + 1, 3),\n",
    "        np.float32,\n",
    "    ),  # obs\n",
    "    Discrete(8),  # action\n",
    "    dict(),\n",
    ")\n",
    "\n",
    "walkers = {f\"Agent{k}\": walker1 for k in range(defaults_ini[\"num_agents\"])}\n",
    "\n",
    "config = {\n",
    "    \"multiagent\": {\n",
    "        \"policies\": walkers,\n",
    "        \"policy_mapping_fn\": lambda agent_id: agent_id,\n",
    "        \"policies_to_train\": list(walkers.keys())\n",
    "    },\n",
    "    \"framework\": \"torch\",\n",
    "    \"model\": {\n",
    "        \"dim\": 3,\n",
    "        \"conv_filters\": [\n",
    "            [16, [4, 4], 1],\n",
    "            [\n",
    "                32,\n",
    "                [defaults_ini[\"sight_dist\"], 2 * defaults_ini[\"sight_width\"] + 1],\n",
    "                1,\n",
    "            ],\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 20:39:30,800\tWARNING worker.py:1107 -- The actor or task with ID ffffffffffffffffa41fc1586ae77e55a51806cb01000000 cannot be scheduled right now. It requires {CPU: 1.000000} for placement, but this node only has remaining {0.000000/4.000000 CPU, 2.783203 GiB/2.783203 GiB memory, 0.927734 GiB/0.927734 GiB object_store_memory, 1.000000/1.000000 node:10.8.3.4}\n",
      ". In total there are 0 pending tasks and 2 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
      "\u001b[2m\u001b[36m(pid=190900)\u001b[0m 2021-03-28 20:39:35,145\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190900)\u001b[0m 2021-03-28 20:39:35,145\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,159\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,159\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190900)\u001b[0m 2021-03-28 20:39:35,236\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190900)\u001b[0m 2021-03-28 20:39:35,236\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,244\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,244\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190900)\u001b[0m 2021-03-28 20:39:35,310\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190900)\u001b[0m 2021-03-28 20:39:35,310\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,328\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,328\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190900)\u001b[0m 2021-03-28 20:39:35,382\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190900)\u001b[0m 2021-03-28 20:39:35,382\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,455\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,455\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-03-28 20:39:35,514\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-03-28 20:39:35,575\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-03-28 20:39:35,634\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-03-28 20:39:35,697\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-03-28 20:39:35,770\tINFO trainable.py:100 -- Trainable.setup took 17.982 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-03-28 20:39:35,775\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# ray.init()\n",
    "trainer = ppo.PPOTrainer(\n",
    "    env=\"harvest\",\n",
    "    config=config,\n",
    "    logger_creator=lambda cfg: UnifiedLogger(cfg, \"log\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,795\tWARNING deprecation.py:33 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=190901)\u001b[0m 2021-03-28 20:39:35,795\tWARNING deprecation.py:33 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_allow_unknown_configs',\n",
       " '_allow_unknown_subkeys',\n",
       " '_before_evaluate',\n",
       " '_close_logfiles',\n",
       " '_create_logger',\n",
       " '_default_config',\n",
       " '_env_id',\n",
       " '_episodes_total',\n",
       " '_evaluate',\n",
       " '_experiment_id',\n",
       " '_export_model',\n",
       " '_init',\n",
       " '_is_overridden',\n",
       " '_iteration',\n",
       " '_iterations_since_restore',\n",
       " '_local_ip',\n",
       " '_log_result',\n",
       " '_logdir',\n",
       " '_make_workers',\n",
       " '_monitor',\n",
       " '_name',\n",
       " '_open_logfiles',\n",
       " '_override_all_subkeys_if_type_changes',\n",
       " '_policy_class',\n",
       " '_register_if_needed',\n",
       " '_restore',\n",
       " '_restored',\n",
       " '_result_logger',\n",
       " '_save',\n",
       " '_setup',\n",
       " '_stderr_context',\n",
       " '_stderr_fp',\n",
       " '_stderr_logging_handler',\n",
       " '_stderr_stream',\n",
       " '_stdout_context',\n",
       " '_stdout_fp',\n",
       " '_stdout_stream',\n",
       " '_stop',\n",
       " '_sync_filters_if_needed',\n",
       " '_sync_weights_to_workers',\n",
       " '_time_since_restore',\n",
       " '_time_total',\n",
       " '_timesteps_since_restore',\n",
       " '_timesteps_total',\n",
       " '_train',\n",
       " '_trial_info',\n",
       " '_try_recover',\n",
       " '_validate_config',\n",
       " 'callbacks',\n",
       " 'cleanup',\n",
       " 'collect_metrics',\n",
       " 'compute_action',\n",
       " 'compute_actions',\n",
       " 'config',\n",
       " 'default_resource_request',\n",
       " 'delete_checkpoint',\n",
       " 'env_creator',\n",
       " 'execution_plan',\n",
       " 'export_model',\n",
       " 'export_policy_checkpoint',\n",
       " 'export_policy_model',\n",
       " 'get_config',\n",
       " 'get_current_ip',\n",
       " 'get_policy',\n",
       " 'get_state',\n",
       " 'get_weights',\n",
       " 'import_model',\n",
       " 'import_policy_model_from_h5',\n",
       " 'iteration',\n",
       " 'load_checkpoint',\n",
       " 'log_result',\n",
       " 'logdir',\n",
       " 'merge_trainer_configs',\n",
       " 'raw_user_config',\n",
       " 'reset',\n",
       " 'reset_config',\n",
       " 'resource_help',\n",
       " 'restore',\n",
       " 'restore_from_object',\n",
       " 'save',\n",
       " 'save_checkpoint',\n",
       " 'save_to_object',\n",
       " 'set_weights',\n",
       " 'setup',\n",
       " 'step',\n",
       " 'stop',\n",
       " 'train',\n",
       " 'train_buffered',\n",
       " 'train_exec_impl',\n",
       " 'training_iteration',\n",
       " 'trial_id',\n",
       " 'trial_name',\n",
       " 'with_updates',\n",
       " 'workers']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-123417dcb993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_policy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Agent1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mexport_policy_model\u001b[0;34m(self, export_dir, policy_id)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_policy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/export_dir\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \"\"\"\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_policy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mDeveloperAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\u001b[0m in \u001b[0;36mexport_policy_model\u001b[0;34m(self, export_dir, policy_id)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                             \u001b[0mexport_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                             policy_id: PolicyID = DEFAULT_POLICY_ID):\n\u001b[0;32m-> 1029\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolicy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mDeveloperAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/policy/torch_policy.py\u001b[0m in \u001b[0;36mexport_model\u001b[0;34m(self, export_dir)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \"\"\"TODO(sven): implement for torch.\n\u001b[1;32m    604\u001b[0m         \"\"\"\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.export_policy_model(\"log\", \"Agent1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policies': {'Agent0': (ray.rllib.policy.policy_template.PPOTorchPolicy,\n",
       "   Box(0.0, 1.0, (10, 11, 3), float32),\n",
       "   Discrete(8),\n",
       "   {}),\n",
       "  'Agent1': (ray.rllib.policy.policy_template.PPOTorchPolicy,\n",
       "   Box(0.0, 1.0, (10, 11, 3), float32),\n",
       "   Discrete(8),\n",
       "   {}),\n",
       "  'Agent2': (ray.rllib.policy.policy_template.PPOTorchPolicy,\n",
       "   Box(0.0, 1.0, (10, 11, 3), float32),\n",
       "   Discrete(8),\n",
       "   {}),\n",
       "  'Agent3': (ray.rllib.policy.policy_template.PPOTorchPolicy,\n",
       "   Box(0.0, 1.0, (10, 11, 3), float32),\n",
       "   Discrete(8),\n",
       "   {})},\n",
       " 'policy_mapping_fn': <function __main__.<lambda>(agent_id)>,\n",
       " 'policies_to_train': ['Agent0', 'Agent1', 'Agent2', 'Agent3'],\n",
       " 'observation_fn': None,\n",
       " 'replay_mode': 'independent',\n",
       " 'count_steps_by': 'env_steps'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"config\"][\"multiagent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_reward_max': 9.0,\n",
       " 'episode_reward_min': 3.0,\n",
       " 'episode_reward_mean': 6.0,\n",
       " 'episode_len_mean': 1002.0,\n",
       " 'episodes_this_iter': 2,\n",
       " 'policy_reward_min': {'Agent0': 0.0,\n",
       "  'Agent1': 0.0,\n",
       "  'Agent2': 3.0,\n",
       "  'Agent3': 0.0},\n",
       " 'policy_reward_max': {'Agent0': 2.0,\n",
       "  'Agent1': 0.0,\n",
       "  'Agent2': 7.0,\n",
       "  'Agent3': 0.0},\n",
       " 'policy_reward_mean': {'Agent0': 1.0,\n",
       "  'Agent1': 0.0,\n",
       "  'Agent2': 5.0,\n",
       "  'Agent3': 0.0},\n",
       " 'custom_metrics': {},\n",
       " 'hist_stats': {'episode_reward': [9.0, 3.0],\n",
       "  'episode_lengths': [1002, 1002],\n",
       "  'policy_Agent0_reward': [2.0, 0.0],\n",
       "  'policy_Agent1_reward': [0.0, 0.0],\n",
       "  'policy_Agent2_reward': [7.0, 3.0],\n",
       "  'policy_Agent3_reward': [0.0, 0.0]},\n",
       " 'sampler_perf': {'mean_env_wait_ms': 1.111176417864066,\n",
       "  'mean_raw_obs_processing_ms': 0.3072834801280695,\n",
       "  'mean_inference_ms': 11.543739860740558,\n",
       "  'mean_action_processing_ms': 0.19977010529616784},\n",
       " 'off_policy_estimator': {},\n",
       " 'num_healthy_workers': 2,\n",
       " 'timesteps_total': 4000,\n",
       " 'timers': {'sample_time_ms': 26727.227,\n",
       "  'sample_throughput': 149.66,\n",
       "  'learn_time_ms': 125316.034,\n",
       "  'learn_throughput': 31.919,\n",
       "  'update_time_ms': 3.795},\n",
       " 'info': {'learner': {'Agent0': {'allreduce_latency': 0.0,\n",
       "    'cur_kl_coeff': 0.2,\n",
       "    'cur_lr': 5e-05,\n",
       "    'total_loss': -0.02375462924828753,\n",
       "    'policy_loss': -0.03605242964113131,\n",
       "    'vf_loss': 0.009801686421269551,\n",
       "    'vf_explained_var': 0.5681598,\n",
       "    'kl': 0.01248059349018149,\n",
       "    'entropy': 2.062639020383358,\n",
       "    'entropy_coeff': 0.0},\n",
       "   'Agent1': {'allreduce_latency': 0.0,\n",
       "    'cur_kl_coeff': 0.2,\n",
       "    'cur_lr': 5e-05,\n",
       "    'total_loss': 0.08862316445447505,\n",
       "    'policy_loss': -0.04650180559838191,\n",
       "    'vf_loss': 0.1320662754587829,\n",
       "    'vf_explained_var': 0.49142584,\n",
       "    'kl': 0.01529346447205171,\n",
       "    'entropy': 2.0629864558577538,\n",
       "    'entropy_coeff': 0.0},\n",
       "   'Agent2': {'allreduce_latency': 0.0,\n",
       "    'cur_kl_coeff': 0.2,\n",
       "    'cur_lr': 5e-05,\n",
       "    'total_loss': 0.07279188901884481,\n",
       "    'policy_loss': -0.0477250840049237,\n",
       "    'vf_loss': 0.11857299692928791,\n",
       "    'vf_explained_var': 0.48753282,\n",
       "    'kl': 0.009719882480567321,\n",
       "    'entropy': 2.0686375945806503,\n",
       "    'entropy_coeff': 0.0},\n",
       "   'Agent3': {'allreduce_latency': 0.0,\n",
       "    'cur_kl_coeff': 0.2,\n",
       "    'cur_lr': 5e-05,\n",
       "    'total_loss': -0.02413189713843167,\n",
       "    'policy_loss': -0.029237630747957155,\n",
       "    'vf_loss': 0.002605741039133136,\n",
       "    'vf_explained_var': 0.75025445,\n",
       "    'kl': 0.012499977194238454,\n",
       "    'entropy': 2.0637534633278847,\n",
       "    'entropy_coeff': 0.0}},\n",
       "  'num_steps_sampled': 4000,\n",
       "  'num_steps_trained': 4000},\n",
       " 'done': False,\n",
       " 'episodes_total': 2,\n",
       " 'training_iteration': 1,\n",
       " 'experiment_id': '20dbd562df8e4510a7dbab69da6945d7',\n",
       " 'date': '2021-03-28_20-42-07',\n",
       " 'timestamp': 1616960527,\n",
       " 'time_this_iter_s': 152.07034420967102,\n",
       " 'time_total_s': 152.07034420967102,\n",
       " 'pid': 188471,\n",
       " 'hostname': 'quinn-Latitude-3340',\n",
       " 'node_ip': '10.8.3.4',\n",
       " 'config': {'num_workers': 2,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'create_env_on_driver': False,\n",
       "  'rollout_fragment_length': 200,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'num_gpus': 0,\n",
       "  'train_batch_size': 4000,\n",
       "  'model': {'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': [[16, [4, 4], 1], [32, [10, 11], 1]],\n",
       "   'conv_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'num_framestacks': 'auto',\n",
       "   'dim': 3,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'lstm_use_prev_action_reward': -1,\n",
       "   'framestack': True},\n",
       "  'optimizer': {},\n",
       "  'gamma': 0.99,\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env_config': {},\n",
       "  'env': 'harvest',\n",
       "  'normalize_actions': False,\n",
       "  'clip_rewards': None,\n",
       "  'clip_actions': True,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'lr': 5e-05,\n",
       "  'monitor': False,\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  '_use_trajectory_view_api': True,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': None,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'memory': 0,\n",
       "  'object_store_memory': 0,\n",
       "  'memory_per_worker': 0,\n",
       "  'object_store_memory_per_worker': 0,\n",
       "  'input': 'sampler',\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {'Agent0': (ray.rllib.policy.policy_template.PPOTorchPolicy,\n",
       "     Box(0.0, 1.0, (10, 11, 3), float32),\n",
       "     Discrete(8),\n",
       "     {}),\n",
       "    'Agent1': (ray.rllib.policy.policy_template.PPOTorchPolicy,\n",
       "     Box(0.0, 1.0, (10, 11, 3), float32),\n",
       "     Discrete(8),\n",
       "     {}),\n",
       "    'Agent2': (ray.rllib.policy.policy_template.PPOTorchPolicy,\n",
       "     Box(0.0, 1.0, (10, 11, 3), float32),\n",
       "     Discrete(8),\n",
       "     {}),\n",
       "    'Agent3': (ray.rllib.policy.policy_template.PPOTorchPolicy,\n",
       "     Box(0.0, 1.0, (10, 11, 3), float32),\n",
       "     Discrete(8),\n",
       "     {})},\n",
       "   'policy_mapping_fn': <function __main__.<lambda>(agent_id)>,\n",
       "   'policies_to_train': ['Agent0', 'Agent1', 'Agent2', 'Agent3'],\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent',\n",
       "   'count_steps_by': 'env_steps'},\n",
       "  'logger_config': None,\n",
       "  'replay_sequence_length': 1,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 1.0,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 30,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'simple_optimizer': True,\n",
       "  '_fake_gpus': False,\n",
       "  'vf_share_layers': -1},\n",
       " 'time_since_restore': 152.07034420967102,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 1,\n",
       " 'perf': {'cpu_util_percent': 45.81751152073733,\n",
       "  'ram_util_percent': 86.62350230414748}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-1\n",
      "events.out.tfevents.1616797063.quinn-Latitude-3340\n",
      "events.out.tfevents.1616798483.quinn-Latitude-3340\n",
      "events.out.tfevents.1616941169.quinn-Latitude-3340\n",
      "events.out.tfevents.1616941192.quinn-Latitude-3340\n",
      "events.out.tfevents.1616943650.quinn-Latitude-3340\n",
      "events.out.tfevents.1616953298.quinn-Latitude-3340\n",
      "events.out.tfevents.1616957917.quinn-Latitude-3340\n",
      "events.out.tfevents.1616958578.quinn-Latitude-3340\n",
      "events.out.tfevents.1616959652.quinn-Latitude-3340\n",
      "events.out.tfevents.1616959673.quinn-Latitude-3340\n",
      "events.out.tfevents.1616960168.quinn-Latitude-3340\n",
      "events.out.tfevents.1616960182.quinn-Latitude-3340\n",
      "events.out.tfevents.1616960208.quinn-Latitude-3340\n",
      "events.out.tfevents.1616960247.quinn-Latitude-3340\n",
      "events.out.tfevents.1616960357.quinn-Latitude-3340\n",
      "params.json\n",
      "params.pkl\n",
      "progress.csv\n",
      "result.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!ls log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.334471</td>\n",
       "      <td>-0.051019</td>\n",
       "      <td>0.383098</td>\n",
       "      <td>0.440263</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>2.065266</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8000</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.136420</td>\n",
       "      <td>-0.052705</td>\n",
       "      <td>0.185611</td>\n",
       "      <td>0.558235</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>2.040155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12000</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.291126</td>\n",
       "      <td>-0.059521</td>\n",
       "      <td>0.347306</td>\n",
       "      <td>0.527838</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>2.021533</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.027325</td>\n",
       "      <td>-0.038971</td>\n",
       "      <td>0.064254</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>2.066390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.027325</td>\n",
       "      <td>-0.038971</td>\n",
       "      <td>0.064254</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>2.066390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>-0.024132</td>\n",
       "      <td>-0.029238</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.750254</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>2.063753</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1          2       3   4   5      6      7   8   9   ...   82   83  \\\n",
       "0  16.0  11.0  13.500000  1002.0   2   2   4000  False   2   1  ...  0.0  0.2   \n",
       "1  16.0   8.0  12.333333  1002.0   4   2   8000  False   6   2  ...  0.0  0.2   \n",
       "2  16.0   8.0  11.600000  1002.0   4   2  12000  False  10   3  ...  0.0  0.2   \n",
       "3  11.0   7.0   9.000000  1002.0   2   2   4000  False   2   1  ...  0.0  0.2   \n",
       "4  11.0   7.0   9.000000  1002.0   2   2   4000  False   2   1  ...  0.0  0.2   \n",
       "5   9.0   3.0   6.000000  1002.0   2   2   4000  False   2   1  ...  0.0  0.2   \n",
       "\n",
       "        84        85        86        87        88        89        90   91  \n",
       "0  0.00005  0.334471 -0.051019  0.383098  0.440263  0.011957  2.065266  0.0  \n",
       "1  0.00005  0.136420 -0.052705  0.185611  0.558235  0.017568  2.040155  0.0  \n",
       "2  0.00005  0.291126 -0.059521  0.347306  0.527838  0.016709  2.021533  0.0  \n",
       "3  0.00005  0.027325 -0.038971  0.064254  0.497110  0.010209  2.066390  0.0  \n",
       "4  0.00005  0.027325 -0.038971  0.064254  0.497110  0.010209  2.066390  0.0  \n",
       "5  0.00005 -0.024132 -0.029238  0.002606  0.750254  0.012500  2.063753  0.0  \n",
       "\n",
       "[6 rows x 92 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"log/progress.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5576\n",
      "-rw-rw-r-- 1 quinn quinn 5508984 Mar 28 20:06 checkpoint-1\n",
      "-rw-rw-r-- 1 quinn quinn   11530 Mar 26 22:24 events.out.tfevents.1616797063.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn      40 Mar 26 22:41 events.out.tfevents.1616798483.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn      40 Mar 28 15:19 events.out.tfevents.1616941169.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn      40 Mar 28 15:19 events.out.tfevents.1616941192.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn      40 Mar 28 16:02 events.out.tfevents.1616943650.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn   61791 Mar 28 18:50 events.out.tfevents.1616953298.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn   11812 Mar 28 20:04 events.out.tfevents.1616957917.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn   11812 Mar 28 20:10 events.out.tfevents.1616958578.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn       0 Mar 28 20:27 events.out.tfevents.1616959652.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn       0 Mar 28 20:27 events.out.tfevents.1616959673.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn       0 Mar 28 20:36 events.out.tfevents.1616960168.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn       0 Mar 28 20:36 events.out.tfevents.1616960182.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn       0 Mar 28 20:36 events.out.tfevents.1616960208.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn       0 Mar 28 20:37 events.out.tfevents.1616960247.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn   11782 Mar 28 20:42 events.out.tfevents.1616960357.quinn-Latitude-3340\n",
      "-rw-rw-r-- 1 quinn quinn     954 Mar 28 20:39 params.json\n",
      "-rw-rw-r-- 1 quinn quinn    4440 Mar 28 20:39 params.pkl\n",
      "-rw-rw-r-- 1 quinn quinn    6511 Mar 28 20:42 progress.csv\n",
      "-rw-rw-r-- 1 quinn quinn   43042 Mar 28 20:42 result.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "\n",
    "# with io.open(\"log/result.json\") as file: \n",
    "#    all_results = json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.callbacks import DefaultCallbacks\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.evaluation import MultiAgentEpisode, RolloutWorker\n",
    "from ray.rllib.policy import Policy\n",
    "from typing import Dict\n",
    "\n",
    "class SaveCheckpointsCallback(DefaultCallbacks): \n",
    "    \n",
    "    def on_episode_end(\n",
    "        self, *, \n",
    "        worker: RolloutWorker, \n",
    "        base_env: BaseEnv,\n",
    "        policies: Dict[str, Policy], \n",
    "        episode: MultiAgentEpisode,\n",
    "        env_index: int, \n",
    "        **kwargs\n",
    "    ):\n",
    "        for agent_id, policy in policies.items(): \n",
    "            policy.export_model(f\"log/{agent_id}\")\n",
    "            \n",
    "        if self.legacy_callbacks.get(\"on_episode_end\"):\n",
    "            self.legacy_callbacks[\"on_episode_end\"]({\n",
    "                \"env\": base_env,\n",
    "                \"policy\": policies,\n",
    "                \"episode\": episode,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"multiagent\": {\n",
    "        \"policies\": walkers,\n",
    "        \"policy_mapping_fn\": lambda agent_id: agent_id,\n",
    "        \"policies_to_train\": list(walkers.keys()), \n",
    "        \"checkpoint_at_end\": True\n",
    "    },\n",
    "    \"framework\": \"torch\",\n",
    "    \"model\": {\n",
    "        \"dim\": 3,\n",
    "        \"conv_filters\": [\n",
    "            [16, [4, 4], 1],\n",
    "            [\n",
    "                32,\n",
    "                [defaults_ini[\"sight_dist\"], 2 * defaults_ini[\"sight_width\"] + 1],\n",
    "                1,\n",
    "            ],\n",
    "        ],\n",
    "    },\n",
    "    #\"callbacks\": SaveCheckpointsCallback\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-28 21:31:12,229\tWARNING worker.py:1107 -- The actor or task with ID ffffffffffffffff1527e7240dfab35c3db907a401000000 cannot be scheduled right now. It requires {CPU: 1.000000} for placement, but this node only has remaining {0.000000/4.000000 CPU, 2.783203 GiB/2.783203 GiB memory, 0.927734 GiB/0.927734 GiB object_store_memory, 1.000000/1.000000 node:10.8.3.4}\n",
      ". In total there are 0 pending tasks and 2 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-a19bb0cd97f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer = ppo.PPOTrainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"harvest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlogger_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnifiedLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         def _init(self, config: TrainerConfigDict,\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mlogger_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_logger_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, logger_creator)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0msetup_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msetup_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mSETUP_TIME_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mget_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;31m# Evaluation setup.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, config, env_creator)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# Creating all workers (excluding evaluation workers).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             self.workers = self._make_workers(\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0menv_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mvalidate_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36m_make_workers\u001b[0;34m(self, env_creator, validate_env, policy_class, config, num_workers)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mWorkerSet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mWorkerSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \"\"\"\n\u001b[0;32m--> 725\u001b[0;31m         return WorkerSet(\n\u001b[0m\u001b[1;32m    726\u001b[0m             \u001b[0menv_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mvalidate_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, logdir, _setup)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m# to not be forced to create an Env on the local worker.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remote_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 remote_spaces = ray.get(self.remote_workers(\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeach_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     lambda p, pid: (pid, p.observation_space, p.action_space)))\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_enabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_client_hook_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mlast_task_error_raise_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0;31m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         values, debugger_breakpoint = worker.get_objects(\n\u001b[0m\u001b[1;32m   1449\u001b[0m             object_refs, timeout=timeout)\n\u001b[1;32m   1450\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cpr-reputation/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mtimeout_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         data_metadata_pairs = self.core_worker.get_objects(\n\u001b[0m\u001b[1;32m    310\u001b[0m             object_refs, self.current_task_id, timeout_ms)\n\u001b[1;32m    311\u001b[0m         \u001b[0mdebugger_breakpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = ppo.PPOTrainer(\n",
    "    env=\"harvest\",\n",
    "    config=config,\n",
    "    logger_creator=lambda cfg: UnifiedLogger(cfg, \"log\"),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    results = trainer.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 13:15 \u001b[01;34mtrain_fn_2021-03-29_13-12-41\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 13:28 \u001b[01;34mtrain_fn_2021-03-29_13-28-25\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 13:32 \u001b[01;34mtrain_fn_2021-03-29_13-29-19\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 13:36 \u001b[01;34mtrain_fn_2021-03-29_13-36-22\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:03 \u001b[01;34mtrain_fn_2021-03-29_13-37-56\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:07 \u001b[01;34mtrain_fn_2021-03-29_14-04-40\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:10 \u001b[01;34mtrain_fn_2021-03-29_14-07-31\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:10 \u001b[01;34mtrain_fn_2021-03-29_14-10-21\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:22 \u001b[01;34mtrain_fn_2021-03-29_14-22-46\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:23 \u001b[01;34mtrain_fn_2021-03-29_14-23-38\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:24 \u001b[01;34mtrain_fn_2021-03-29_14-24-38\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:25 \u001b[01;34mtrain_fn_2021-03-29_14-25-27\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:26 \u001b[01;34mtrain_fn_2021-03-29_14-26-50\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:31 \u001b[01;34mtrain_fn_2021-03-29_14-28-42\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:37 \u001b[01;34mtrain_fn_2021-03-29_14-37-27\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:38 \u001b[01;34mtrain_fn_2021-03-29_14-38-43\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:40 \u001b[01;34mtrain_fn_2021-03-29_14-40-13\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 14:41 \u001b[01;34mtrain_fn_2021-03-29_14-40-55\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 15:40 \u001b[01;34mtrain_fn_2021-03-29_15-34-48\u001b[0m/\n",
      "drwxrwxr-x 3 quinn quinn 4096 Mar 29 17:22 \u001b[01;34mtrain_fn_2021-03-29_17-18-24\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -l ~/ray_results | grep train_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//home/quinn/ray_results/train_fn_2021-03-29_17-18-24'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def all_dirs_under(path):\n",
    "    \"\"\"Iterates through all files that are under the given path.\"\"\"\n",
    "    for cur_path, dirnames, filenames in os.walk(path):\n",
    "        for dir_ in dirnames: \n",
    "            yield os.path.join(cur_path, dir_)\n",
    "\n",
    "def latest_dir(path): \n",
    "    return max(all_dirs_under(path), key=os.path.getmtime)\n",
    "\n",
    "to_restore = latest_dir(\"//home/quinn/ray_results\")\n",
    "to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_to_checkpoint(to_restore_path: str): \n",
    "    for cur_path, dirnames, _ in os.walk(to_restore_path): \n",
    "        for dir_ in dirnames: \n",
    "            if dir_.startswith(\"train_fn_\"):\n",
    "                # print(os.path.join(cur_path, dir_))\n",
    "                for cur_path_, dirnames_, _ in os.walk(os.path.join(cur_path, dir_)): \n",
    "                    for dir__ in dirnames_:                     \n",
    "                        if dir__.startswith(\"checkpoint_\"): \n",
    "                            return os.path.join(cur_path_, dir__)\n",
    "\n",
    "checkpoint = walk_to_checkpoint(\n",
    "    latest_dir(\n",
    "        \"//home/quinn/ray_results\"\n",
    "    )\n",
    ")\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//home/quinn/ray_results/train_fn_2021-03-29_20-08-33/train_fn_28297_00000_0_2021-03-29_20-08-33/checkpoint_tmp095c77'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def retrieve_checkpoint(path: str = \"//home/quinn/ray_results\", prefix: str = \"train_fn\") -> str: \n",
    "\n",
    "    def all_dirs_under(path):\n",
    "        \"\"\"Iterates through all files that are under the given path.\"\"\"\n",
    "        for cur_path, dirnames, filenames in os.walk(path):\n",
    "            for dir_ in dirnames: \n",
    "                yield os.path.join(cur_path, dir_)\n",
    "\n",
    "    def retrieve_checkpoints(paths: List[str]) -> List[str]:\n",
    "        checkpoints = list()\n",
    "        for path in paths: \n",
    "            for cur_path, dirnames, _ in os.walk(path): \n",
    "                for dirname in dirnames: \n",
    "                    if dirname.startswith(\"checkpoint_\"): \n",
    "                        checkpoints.append(os.path.join(cur_path, dirname))\n",
    "        return checkpoints\n",
    "    \n",
    "    sorted_checkpoints = retrieve_checkpoints(\n",
    "        sorted(\n",
    "            filter(\n",
    "                lambda x: x.startswith(f\"{path}/{prefix}\"), all_dirs_under(path)\n",
    "            ), \n",
    "            key=os.path.getmtime\n",
    "        )\n",
    "    )[::-1]\n",
    "    \n",
    "    for checkpoint in sorted_checkpoints:\n",
    "        if checkpoint is not None: \n",
    "            return checkpoint\n",
    "    return None\n",
    "\n",
    "retrieve_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\n",
      "drwxrwxr-x 2 quinn quinn 4096 Mar 29 20:08 .\n",
      "drwxrwxr-x 4 quinn quinn 4096 Mar 29 20:08 ..\n",
      "-rw-rw-r-- 1 quinn quinn    0 Mar 29 20:08 .is_checkpoint\n",
      "-rw-rw-r-- 1 quinn quinn    0 Mar 29 20:08 .null_marker\n",
      "-rw-rw-r-- 1 quinn quinn    0 Mar 29 20:08 .temp_marker\n",
      "-rw-rw-r-- 1 quinn quinn  181 Mar 29 20:08 .tune_metadata\n"
     ]
    }
   ],
   "source": [
    "!ls -la //home/quinn/ray_results/train_fn_2021-03-29_20-08-33/train_fn_28297_00000_0_2021-03-29_20-08-33/checkpoint_tmp095c77/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import permutation\n",
    "permutation(list(map(lambda x: x == 5, [4,5,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toward video proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celluloid import Camera\n",
    "from IPython.display import Video\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from cpr_reputation import board\n",
    "from cpr_reputation.utils import retrieve_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = retrieve_checkpoint(\"//home/quinn/ray_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint \n",
    "# run episode \n",
    "# with Camera calls in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
